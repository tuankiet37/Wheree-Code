{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBVgNY4DuKPu"
      },
      "source": [
        "# Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5V5budo6kPkn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import multiprocessing\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import openai\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxBuRbLQxIvW"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "moSWXTkWk3op"
      },
      "outputs": [],
      "source": [
        "def prepare_file(file_path, file_header):\n",
        "    try:\n",
        "        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:\n",
        "            with open(file_path, 'w', newline='') as file:\n",
        "                file.write(file_header)\n",
        "        print(f\"Crawler - {file_path} - File path checking completed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Crawler - File path error..!! - {file_header} - {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F2eOlxa8mhF8"
      },
      "outputs": [],
      "source": [
        "write_lock = multiprocessing.Lock()\n",
        "def writeMainInfo(result_entry: dict, file_name: str) -> None:\n",
        "    try:\n",
        "        with write_lock:\n",
        "            with open(file_name, mode='a', newline='', encoding='utf-8') as file:\n",
        "                writer = csv.DictWriter(f=file, quoting=csv.QUOTE_MINIMAL, fieldnames=result_entry.keys())\n",
        "                writer.writerow(result_entry)\n",
        "    except Exception as e:\n",
        "        print(f'Crawler - FAILED at \"writeMainInfo()\" - {e}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sKNrDbejmm1_"
      },
      "outputs": [],
      "source": [
        "def collectRecordsTobeChecked(success_path: str,df_source: str, header: str) -> pd.DataFrame:\n",
        "    try:\n",
        "        prepare_file(success_path, header)\n",
        "        # df_source = pd.read_csv(source_path,on_bad_lines=\"skip\",engine='python', quotechar='\"')\n",
        "        df_success = pd.read_csv(success_path,on_bad_lines=\"skip\",engine='python', quotechar='\"') if os.path.exists(success_path) else pd.DataFrame(columns=['code'])\n",
        "\n",
        "        # processing_df = df_source[len(df_success)+1::]\n",
        "        processing_df = df_source[~df_source['code'].isin(set(df_success['code']))]\n",
        "\n",
        "        print(f\"Total batch records: {len(df_source)} records, \"\n",
        "                        f\"Skipped: {len(df_source)-len(processing_df)} records, \"\n",
        "                        f\"Ordered to be processed: {len(processing_df)}\")\n",
        "        return processing_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Crawler - FAILED at 'collectRecordsTobeChecked()' - {e}.\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def promptGPT(prompt, api_key, base_url):\n",
        "    client = openai.OpenAI(api_key= api_key, base_url = base_url)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        max_tokens=500,\n",
        "        temperature=0.7,  # More creative, so more detail is generated\n",
        "        top_p=0.9,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        n=1\n",
        "    )\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JloFMNwk0bak"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_prompt_main(review, name, address, cate_lst): \n",
        "    promt = f\"\"\"\n",
        "    You are tasked with creating content and classifying data for the specified BRAND using the provided customer reviews. Follow these instructions to complete both tasks:\n",
        "    First task: Write an engaging 'Overview' page introduction for the BRAND based on the reviews.\n",
        "    Overview Page Content:\n",
        "\n",
        "    Objective: Write a captivating 'Overview' page introduction that showcases the BRAND’s strengths, features, and overall appeal.\n",
        "    Content Focus: Highlight the BRAND's visual appeal, key features, and unique attributes based on customer reviews. Exclude any references to guests or their experiences.\n",
        "    SEO Optimization: Naturally integrate relevant keywords to enhance search engine visibility while ensuring the content is engaging and easy to read.\n",
        "    Tone and Style: Use a friendly, professional, and descriptive tone. Write in a neutral, third-person perspective, avoiding pronouns like \"we,\" \"our,\" \"us,\" \"they,\" \"their,\" or \"them.\"\n",
        "    Special Note: If the BRAND name is not in English, use its original form.\n",
        "    Format: Provide only the text of the introduction without a title.\n",
        "\n",
        "    Content paragraph must be about 240 words. WRITE IT LONGER AND MORE DETAILED\n",
        "    STRICTLY FOLLOW Length of content : *** The CONTENT MUST BE ABOUT 240 WORDS. ABOUT 330 TOKEN. *** .\n",
        "    \n",
        "    Second task: Classify the BRAND into the most suitable category and summarize its advantages and disadvantages based on the reviews.\n",
        "    Brand Classification and Summary:\n",
        "\n",
        "    Objective: Assign a suitable category to the BRAND and summarize its advantages and disadvantages based on customer reviews.\n",
        "    Brand Categorization: Select the most fitting category from the provided list of categories.\n",
        "    Summary Requirements: Write two separate summaries:\n",
        "    Advantages: Provide a two-sentence summary, with each sentence up to 30 words, detailing the BRAND’s positive aspects.\n",
        "    Disadvantages: Provide a two-sentence summary, with each sentence up to 30 words, detailing the BRAND’s negative aspects.\n",
        "    SEO Optimization: Ensure summaries adhere to SEO best practices for clarity and relevance.\n",
        "    Tone and Style: Maintain a neutral, informative, and objective tone in a third-person narrative, avoiding personal pronouns.\n",
        "    Format:\n",
        "    Brand Category: [Appropriate category]\n",
        "    Brand Advantage: [First advantage sentence]####[Second advantage sentence]\n",
        "    Brand Disadvantage: [First disadvantage sentence]####[Second disadvantage sentence]\n",
        "    Length: Keep each summary approximately 60-80 tokens.\n",
        "    Inputs:\n",
        "\n",
        "    BRAND: {name}\n",
        "    BRAND_ADDRESS: {address}\n",
        "    Reviews: {review}\n",
        "    List of Categories: {cate_lst}\n",
        "    Ideal Output Format:\n",
        "\n",
        "    Overview Page Content: [Overview Page Content Output]\n",
        "    Brand Category: [Appropriate category]\n",
        "    Brand Advantage: [First advantage sentence]####[Second advantage sentence]\n",
        "    Brand Disadvantage: [First disadvantage sentence]####[Second disadvantage sentence]\n",
        "    Ensure the content and classifications accurately reflect the BRAND as described in the reviews, delivering a detailed overview and precise categorization.\"\"\"\n",
        "    return promt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_response(response):\n",
        "    content, category, advantage, disadvantage = None, None, None, None\n",
        "\n",
        "    text = response['choices'][0].message.content\n",
        "\n",
        "    content = text.split('Brand Category:')[0].strip()\n",
        "    content = content.replace('Overview Page Content:', '').strip()\n",
        "    content = content.replace('\\n', ' ')\n",
        "\n",
        "    category_match = re.search(r'Brand Category:\\s*(.*)\\s*', text)\n",
        "    if category_match:\n",
        "        category = category_match.group(1).strip()\n",
        "    else:\n",
        "        category = text.split('Brand Advantage:')[0].strip()\n",
        "        category = text.split('Brand Category:')[1].split('Brand Advantage:')[0].strip()\n",
        "        category = category.replace('Overview Page Content:', '').strip()\n",
        "        category = category.replace('*', '').strip()\n",
        "\n",
        "    advantage = text.split('Brand Advantage:')[1].split('Brand Disadvantage:')[0].strip()\n",
        "    advantage = [x.strip() for x in advantage.split('####') if x.strip()]\n",
        "\n",
        "    disadvantage = text.split('Brand Disadvantage:')[1].strip()\n",
        "    disadvantage = [x.strip() for x in disadvantage.split('####') if x.strip()]\n",
        "\n",
        "    \n",
        "    return content, category, advantage, disadvantage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "catefile = r\"D:\\Wheree_Kiet\\Input\\category.csv\"\n",
        "cate_df = pd.read_csv(catefile)\n",
        "cate_lst = cate_df['category'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = 'YOUR_API_KEY'\n",
        "base_url=\"https://open.keyai.shop/v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crawler - D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\pros_cons.csv - File path checking completed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27308\\2868800689.py:11: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  main_df = pd.read_csv(r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\main.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crawler - D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\main_content.csv - File path checking completed.\n",
            "Total batch records: 221103 records, Skipped: 221103 records, Ordered to be processed: 0\n"
          ]
        }
      ],
      "source": [
        "source_path = r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\grouped_reviews.csv\"\n",
        "base_dir = r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\"\n",
        "success_path = os.path.join(base_dir, 'main_content.csv')\n",
        "header = 'code,content,type,category,input_token,output_token\\n'\n",
        "\n",
        "pros_cons = os.path.join(base_dir, 'pros_cons.csv')\n",
        "header_pros_cons = 'code,advantages,disadvantages\\n'\n",
        "prepare_file(pros_cons, header_pros_cons)\n",
        "\n",
        "\n",
        "main_df = pd.read_csv(r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\main.csv\")\n",
        "map_name = dict(zip(main_df['code'], main_df['orignalname']))\n",
        "map_address = dict(zip(main_df['code'], main_df['fulladdress']))\n",
        "df = pd.read_csv(source_path)\n",
        "\n",
        "\n",
        "df =  collectRecordsTobeChecked(success_path, df, header)\n",
        "df['name'] = df['code'].map(map_name)\n",
        "df['address'] = df['code'].map(map_address)\n",
        "max_word  = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_row(row):\n",
        "\n",
        "    review = row['content'] if 'content' in row else (row['reviews'] if 'reviews' in row else row['review'])\n",
        "    \n",
        "    #review = \" \".join(review.split(' ')[:max_word])\n",
        "    \n",
        "    name = row['name']\n",
        "    address = row['address']\n",
        "    \n",
        "\n",
        "    prompt = create_prompt_main(review, name, address, cate_lst)\n",
        "    \n",
        "\n",
        "    response = promptGPT(prompt, api_key, base_url)\n",
        "    response = dict(response)\n",
        "    \n",
        "    if response['choices'][0].message.content:\n",
        "        content, category, advantage, disadvantage = extract_response(response)\n",
        "\n",
        "        if len(content.split(' ')) > 100 and category in cate_lst and len(advantage) == len(disadvantage) == 2:\n",
        "            # Write main info\n",
        "            result_entry_main = {\n",
        "                'code': row['code'],\n",
        "                'content': content,\n",
        "                'type': 'HOME.S1.P1.C1',\n",
        "                'category': category,\n",
        "                'input_token': response['usage'].prompt_tokens,\n",
        "                'output_token': response['usage'].completion_tokens\n",
        "            }\n",
        "            writeMainInfo(result_entry_main, success_path)\n",
        "            \n",
        "            for i in range(len(advantage)):\n",
        "                result_entry_pros_cons = {\n",
        "                    'code': row['code'],\n",
        "                    'advantages': advantage[i],\n",
        "                    'advantages': disadvantage[i]\n",
        "                }\n",
        "                writeMainInfo(result_entry_pros_cons, pros_cons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing rows: 100%|██████████| 1/1 [00:04<00:00,  4.62s/it]\n"
          ]
        }
      ],
      "source": [
        "with ProcessPoolExecutor(max_workers=30) as executor:  \n",
        "    futures = [executor.submit(process_row, row) for _, row in df.iterrows()]\n",
        "    \n",
        "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing rows\"):\n",
        "        try:\n",
        "            future.result() \n",
        "        except Exception as e:\n",
        "            # print(f\"Error processing row\")\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
