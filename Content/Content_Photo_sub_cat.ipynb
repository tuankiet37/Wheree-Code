{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBVgNY4DuKPu"
      },
      "source": [
        "# Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5V5budo6kPkn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import multiprocessing\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import openai\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxBuRbLQxIvW"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "moSWXTkWk3op"
      },
      "outputs": [],
      "source": [
        "def prepare_file(file_path, file_header):\n",
        "    try:\n",
        "        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:\n",
        "            with open(file_path, 'w', newline='') as file:\n",
        "                file.write(file_header)\n",
        "        print(f\"Crawler - {file_path} - File path checking completed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Crawler - File path error..!! - {file_header} - {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "F2eOlxa8mhF8"
      },
      "outputs": [],
      "source": [
        "write_lock = multiprocessing.Lock()\n",
        "def writeMainInfo(result_entry: dict, file_name: str) -> None:\n",
        "    try:\n",
        "        with write_lock:\n",
        "            with open(file_name, mode='a', newline='', encoding='utf-8') as file:\n",
        "                writer = csv.DictWriter(f=file, quoting=csv.QUOTE_MINIMAL, fieldnames=result_entry.keys())\n",
        "                writer.writerow(result_entry)\n",
        "    except Exception as e:\n",
        "        print(f'Crawler - FAILED at \"writeMainInfo()\" - {e}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sKNrDbejmm1_"
      },
      "outputs": [],
      "source": [
        "def collectRecordsTobeChecked(success_path: str,df_source: str, header: str) -> pd.DataFrame:\n",
        "    try:\n",
        "        prepare_file(success_path, header)\n",
        "        # df_source = pd.read_csv(source_path,on_bad_lines=\"skip\",engine='python', quotechar='\"')\n",
        "        df_success = pd.read_csv(success_path,on_bad_lines=\"skip\",engine='python', quotechar='\"') if os.path.exists(success_path) else pd.DataFrame(columns=['code'])\n",
        "\n",
        "        # processing_df = df_source[len(df_success)+1::]\n",
        "        processing_df = df_source[~df_source['code'].isin(set(df_success['code']))]\n",
        "\n",
        "        print(f\"Total batch records: {len(df_source)} records, \"\n",
        "                        f\"Skipped: {len(df_source)-len(processing_df)} records, \"\n",
        "                        f\"Ordered to be processed: {len(processing_df)}\")\n",
        "        return processing_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Crawler - FAILED at 'collectRecordsTobeChecked()' - {e}.\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def promptGPT(prompt, api_key, base_url):\n",
        "    client = openai.OpenAI(api_key= api_key, base_url = base_url)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        max_tokens=350,\n",
        "        temperature=0.7,  \n",
        "        top_p=0.9,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        n=1\n",
        "    )\n",
        "\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JloFMNwk0bak"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_prompt_photo(review, name, address, subcate_lst, criteria_lst): \n",
        "    promt = f\"\"\"\n",
        "    You are tasked with creating content and classifying data for the specified BRAND using the provided customer reviews. Follow these instructions to complete THREE tasks:\n",
        "    \n",
        "\n",
        "    1.  First task: Write an engaging 'Photo' page introduction for the BRAND based on the reviews.\n",
        "\n",
        "        You are an expert in SEO content writing with a focus on creating engaging and informative content for websites. \n",
        "        First task is to write a concise and compelling content about 'photo' page description for the given BRAND, using customer reviews as your primary source of information.\n",
        "\n",
        "        Instructions:\n",
        "\n",
        "        Content Photo: Introduce the BRAND photo and views, the landscape around the BRAND, focusing on the positive aspects. Do not include any negative information. Do not write about anything else that the brand dont have.Focus only on positive side of photos and Views, Landscape around, Dont write about anything else.\n",
        "        SEO Compliance: Follow SEO best practices to ensure the content is optimized for search engines. Follow the best practices for writing page content.\n",
        "        Length: Write between 180 to 230 words.\n",
        "        Language Use: Avoid using the words \"we\", \"our\", \"us\", \"they\", \"their\", and \"them\" to maintain a neutral tone. Write as third-person narrative, who is an expert in SEO content writing.\n",
        "        Must follow the instructions and write the content as per the guidelines provided. Dont return the intro or paragraph title like \"**Photo Page Description for El Colomaniano**\". Write only the content.\n",
        "\n",
        "        The BRAND name and customer reviews will be provided below:\n",
        "        STRICTLY FOLLOW Length of content : *** The CONTENT MUST BE ABOUT 200 WORDS. ABOUT 220 TOKEN. *** .\n",
        "    ------    \n",
        "    2. Second task: Classify the BRAND into the most suitable category and summarize its advantages and disadvantages based on the reviews.\n",
        "\n",
        "        Brand Classification:\n",
        "        Objective: Assign/Label 3 suitable categories approriate to the BRAND.\n",
        "        Brand Categorization: Select the most fitting category from the provided list of categories.\n",
        "        Format:\n",
        "        Brand Sub-Category: [Appropriate category 1]###[Appropriate category 2]###[Appropriate category 3]\n",
        "    ------\n",
        "    3. Third task:\n",
        "        You are an expert critic responsible for evaluating a brand based on customer reviews. Your goal is to assign scores for each criterion listed below.\n",
        "\n",
        "        Score Range: Each score must be between 6.0 and 9.5, inclusive.\n",
        "        Precision: Scores must be expressed to one decimal place (e.g., 6.1, 7.8, 9.4) and should not be limited to increments of 0.5.\n",
        "        Evaluation: Base your scores strictly on the analysis of the reviews, reflecting the sentiments and insights gathered from them.\n",
        "        Format: Present your findings in the following structured format:\n",
        "        Brand Criteria Score: [Criteria 1]### [Score of Criteria 1]### [Criteria 2]### [Score of Criteria 2]### [Criteria 3]### [Score of Criteria 3],...\n",
        "        Please ensure that your scores accurately reflect the reviews and demonstrate a strict adherence to the specified guidelines\n",
        "    ------\n",
        "    Inputs:\n",
        "    BRAND: {name}\n",
        "    BRAND_ADDRESS: {address}\n",
        "    Reviews: {review}\n",
        "    List of Categories: {subcate_lst}\n",
        "    List of Criteria: {criteria_lst}\n",
        "\n",
        "    Ideal Output Format:\n",
        "    Photo Page Content: [Photo Page Content Output]\n",
        "    Brand Sub-Category: [Appropriate category 1]###[Appropriate category 2]###[Appropriate category 3]\n",
        "    Brand Criteria Score: [Criteria 1]###[Score 1]###[Criteria 2]###[Score 2]###[Criteria 3]###[Score 3],...\n",
        "    Ensure the content and classifications accurately reflect the BRAND as described in the reviews, delivering a detailed overview and precise categorization.\"\"\"\n",
        "    return promt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_response(response):\n",
        "    content, subcategory = None, None\n",
        "\n",
        "    text = response['choices'][0].message.content\n",
        "\n",
        "    content = text.split('Brand Sub-Category:')[0].strip()\n",
        "    content = content.replace('Photo Page Content:', '').strip()\n",
        "    content = content.replace('\\n', ' ')\n",
        "\n",
        "    subcategory = text.split('Brand Sub-Category:')[1].strip()\n",
        "    subcategory = subcategory.split('Brand Criteria Score:')[0].strip()\n",
        "    subcategory = [x.strip() for x in subcategory.split('###')]\n",
        "\n",
        "    criteria = text.split('Brand Criteria Score:')[1].strip()\n",
        "\n",
        "    criteria_data = criteria.split(\"###\")\n",
        "\n",
        "    # criteria_dict = {criteria_data[i]: float(criteria_data[i + 1]) for i in range(0, len(criteria_data), 2)}\n",
        "    criteria_dict = {}\n",
        "    for i in range(0, len(criteria_data), 2):\n",
        "        try:\n",
        "            criteria_dict[criteria_data[i]] = float(criteria_data[i + 1])\n",
        "        except ValueError:\n",
        "            continue  # Skip this loop iteration if conversion to float fails\n",
        "\n",
        "    return content, subcategory, criteria_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "criteriafile = r\"D:\\Wheree_Kiet\\Input\\danhmucdanhgia.csv\"\n",
        "criteria = pd.read_csv(criteriafile)\n",
        "criteria_lst = criteria.groupby('cat')['sub_cat'].apply(list).to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "catefile = r\"D:\\Wheree_Kiet\\Input\\category.csv\"\n",
        "cate_df = pd.read_csv(catefile)\n",
        "cate_lst = cate_df['category'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "subfile = r'D:\\Wheree_Kiet\\Input\\catesub.csv'\n",
        "sub_df = pd.read_csv(subfile)\n",
        "sub_lst = sub_df.groupby('category')['sub_category'].apply(list).to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key = 'YOUR_API_KEY'\n",
        "base_url=\"https://open.keyai.shop/v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_21224\\2656343125.py:8: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  main_df = pd.read_csv(r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\main.csv\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crawler - D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\photo_content.csv - File path checking completed.\n",
            "Total batch records: 221103 records, Skipped: 221095 records, Ordered to be processed: 8\n"
          ]
        }
      ],
      "source": [
        "source_path = r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\grouped_reviews.csv\"\n",
        "base_dir = r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\"\n",
        "success_path = os.path.join(base_dir, 'photo_content.csv')\n",
        "header = 'code,content,type,subcate1,subcate2,subcate3,sub_score,input_token,output_token\\n'\n",
        "\n",
        "\n",
        "main_df = pd.read_csv(r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\main.csv\")\n",
        "main_content = pd.read_csv(r\"D:\\DATA\\2024\\Sep\\Combine\\10_10_2024\\main_content.csv\")\n",
        "map_name = dict(zip(main_df['code'], main_df['orignalname']))\n",
        "map_address = dict(zip(main_df['code'], main_df['fulladdress']))\n",
        "map_category = dict(zip(main_content['code'], main_content['category']))\n",
        "df = pd.read_csv(source_path)\n",
        "\n",
        "\n",
        "df = df[df['code'].isin(main_df['code'])]\n",
        "df =  collectRecordsTobeChecked(success_path, df, header)\n",
        "df['name'] = df['code'].map(map_name)\n",
        "df['address'] = df['code'].map(map_address)\n",
        "df['category'] = df['code'].map(map_category)\n",
        "max_word  = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_row(row):\n",
        "\n",
        "    review = row['content'] if 'content' in row else (row['reviews'] if 'reviews' in row else row['review'])\n",
        "    \n",
        "    review = \" \".join(review.split(' ')[:min(max_word, len(review.split(' ')))])\n",
        "    \n",
        "    name = row['name']\n",
        "    address = row['address']\n",
        "\n",
        "    prompt = create_prompt_photo(review, name, address, sub_lst[row['category']], criteria_lst[row['category']])\n",
        "    \n",
        "\n",
        "    response = promptGPT(prompt, api_key, base_url)\n",
        "    response = dict(response)\n",
        "    \n",
        "    if response['choices'][0].message.content:\n",
        "        content, subcategory, criteria_dict = extract_response(response)\n",
        "\n",
        "        if len(content.split(' ')) > 100:\n",
        "            sub_1 = subcategory[0] if subcategory[0] in sub_lst[row['category']] else None\n",
        "            if sub_1:\n",
        "                sub_1 = sub_1.replace('*', '').strip()\n",
        "                sub_2 = subcategory[1] if subcategory[1] in sub_lst[row['category']] else None\n",
        "                if sub_2:\n",
        "                    sub_2 = sub_2.replace('*', '').strip()\n",
        "                    sub_3 = subcategory[2] if subcategory[2] in sub_lst[row['category']] else None\n",
        "                    if sub_3:\n",
        "                        sub_3 = sub_3.replace('*', '').strip()\n",
        "                    else:\n",
        "                        sub_3 = None\n",
        "                else:\n",
        "                    sub_3 = None\n",
        "            else:\n",
        "                return\n",
        "\n",
        "            # Write main info\n",
        "            result_entry = {\n",
        "                'code': row['code'],\n",
        "                'content': content,\n",
        "                'type': 'PHOTO.S20.P1.C1',\n",
        "                'subcate1': sub_1,\n",
        "                'subcate2': sub_2,\n",
        "                'subcate3': sub_3,\n",
        "                'sub_score': criteria_dict,\n",
        "                'input_token': response['usage'].prompt_tokens,\n",
        "                'output_token': response['usage'].completion_tokens\n",
        "            }\n",
        "            writeMainInfo(result_entry, success_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing rows: 100%|██████████| 1101/1101 [03:13<00:00,  5.70it/s]\n"
          ]
        }
      ],
      "source": [
        "with ProcessPoolExecutor(max_workers=5) as executor:  \n",
        "    futures = [executor.submit(process_row, row) for _, row in df.iterrows()]\n",
        "    \n",
        "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing rows\"):\n",
        "        try:\n",
        "            future.result()\n",
        "        except Exception as e:\n",
        "            # print(f\"Error processing row {e}\")\n",
        "            pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
